{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBOW Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "import os \n",
    "import zipfile\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "\n",
    "\n",
    "def download_data(url, data_dir):\n",
    "    \"\"\"Download a file if not present, and make it sure it's the right size\"\"\"\n",
    "\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    \n",
    "    file_path = os.path.join(data_dir, 'bbc-fulltext.zip')\n",
    "\n",
    "    if not os.path.exists('file_path'):\n",
    "        print('Downloading file...')\n",
    "        filename, _ = urlretrieve(url, file_path)\n",
    "    else:\n",
    "        print('File already exists')\n",
    "\n",
    "    extract_path = os.path.join(data_dir, 'bbc')\n",
    "    if not os.path.exists(extract_path):\n",
    "\n",
    "        with zipfile.ZipFile(\n",
    "            os.path.join(data_dir,'bbc-fulltext.zip'),\n",
    "            'r'\n",
    "        ) as zipf:\n",
    "            zipf.extractall(data_dir)\n",
    "    \n",
    "    else:\n",
    "        print('bbc-fulltext,zip has already been extracted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading file...\n",
      "bbc-fulltext,zip has already been extracted\n"
     ]
    }
   ],
   "source": [
    "url = 'http://mlg.ucd.ie/files/datasets/bbc-fulltext.zip'\n",
    "download_data(url, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_dir):\n",
    "    news_stories = []\n",
    "    print('Reading files')\n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        for fi, f in enumerate(files):\n",
    "            if 'README' in f:\n",
    "                continue\n",
    "            print('.'*fi, f, end='\\r')\n",
    "            with open(os.path.join(root, f), encoding='latin-1') as f:\n",
    "                story = []\n",
    "                for row in f:\n",
    "                    story.append(row.strip())\n",
    "                story = ''.join(story)\n",
    "                news_stories.append(story)\n",
    "    print(f\"\\nDetected {len(news_stories)} stories\")\n",
    "    return news_stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files\n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................ 284.txt........ 284.txt...................................................................................... 284.txt\n",
      "Detected 2225 stories\n",
      "843863 words in the total news set\n",
      "Example words (starts): Musicians to tackle US red tapeMusicians' groups a\n",
      "Example words (end): Hacker threat to Apple's iTunesUsers of Apple's music jukebox iTunes need to update the software to avoid a potential security threat.Hackers can build malicious playlist files which could crash the program and let them seize control of the computer by inserting Trojan code. A new version of iTunes is now available from the Apple website which solves the problem. Security firm iDefence, which notified users of the problem, recommended that users upgrade to iTunes version 4.7.1. The problem affects all users of iTunes - Windows and Mac OS - running versions 4.7 and earlier. Users can automatically upgrade iTunes by opening the \"look for updates\" window in the program. The security firm says users should avoid clicking on or accessing playlist files - which have the file extension of .pls or .m3u - which have come from unknown sources. Itunes is the world's most popular online music store with more than 200 m\n"
     ]
    }
   ],
   "source": [
    "news_stories = read_data(os.path.join('data','bbc'))\n",
    "\n",
    "print(f\"{sum([len(story.split(' ')) for story in news_stories])} words in the total news set\")\n",
    "print('Example words (starts):', news_stories[0][:50])\n",
    "print('Example words (end):', news_stories[-1][:-50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(\n",
    "    num_words = None,\n",
    "    filters = '!\"#$%&()*+,-/:;<=>?@[\\\\]^_{|}~\\t\\n',\n",
    "    lower = True,\n",
    "    split = ' '\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(news_stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vocab = len(tokenizer.word_index.items()) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_sequences = tokenizer.texts_to_sequences(news_stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [2826, 2] (['musicians', 'to']) / Label: 1\n",
      "Input: [2, 2826] (['to', 'musicians']) / Label: 1\n",
      "Input: [2, 1309] (['to', 'tackle']) / Label: 1\n",
      "Input: [1309, 2] (['tackle', 'to']) / Label: 1\n",
      "Input: [1309, 48] (['tackle', 'us']) / Label: 1\n",
      "Input: [48, 1309] (['us', 'tackle']) / Label: 1\n",
      "Input: [48, 1235] (['us', 'red']) / Label: 1\n",
      "Input: [1235, 48] (['red', 'us']) / Label: 1\n",
      "Input: [1235, 24644] (['red', \"tapemusicians'\"]) / Label: 1\n",
      "Input: [24644, 1235] ([\"tapemusicians'\", 'red']) / Label: 1\n",
      "Input: [24644, 880] ([\"tapemusicians'\", 'groups']) / Label: 1\n",
      "Input: [880, 24644] (['groups', \"tapemusicians'\"]) / Label: 1\n",
      "Input: [880, 23] (['groups', 'are']) / Label: 1\n",
      "Input: [23, 880] (['are', 'groups']) / Label: 1\n",
      "Input: [23, 2] (['are', 'to']) / Label: 1\n",
      "Input: [2, 23] (['to', 'are']) / Label: 1\n",
      "Input: [2, 1309] (['to', 'tackle']) / Label: 1\n",
      "Input: [1309, 2] (['tackle', 'to']) / Label: 1\n",
      "Input: [1309, 48] (['tackle', 'us']) / Label: 1\n",
      "Input: [48, 1309] (['us', 'tackle']) / Label: 1\n",
      "Input: [48, 2755] (['us', 'visa']) / Label: 1\n",
      "Input: [2755, 48] (['visa', 'us']) / Label: 1\n",
      "Input: [2755, 3850] (['visa', 'regulations']) / Label: 1\n",
      "Input: [3850, 2755] (['regulations', 'visa']) / Label: 1\n",
      "Input: [3850, 34] (['regulations', 'which']) / Label: 1\n",
      "Input: [34, 3850] (['which', 'regulations']) / Label: 1\n",
      "Input: [34, 23] (['which', 'are']) / Label: 1\n",
      "Input: [23, 34] (['are', 'which']) / Label: 1\n",
      "Input: [23, 2141] (['are', 'blamed']) / Label: 1\n",
      "Input: [2141, 23] (['blamed', 'are']) / Label: 1\n",
      "Input: [2141, 7] (['blamed', 'for']) / Label: 1\n",
      "Input: [7, 2141] (['for', 'blamed']) / Label: 1\n",
      "Input: [7, 24645] (['for', 'hindering']) / Label: 1\n",
      "Input: [24645, 7] (['hindering', 'for']) / Label: 1\n",
      "Input: [24645, 160] (['hindering', 'british']) / Label: 1\n",
      "Input: [160, 24645] (['british', 'hindering']) / Label: 1\n",
      "Input: [160, 24646] (['british', \"acts'\"]) / Label: 1\n",
      "Input: [24646, 160] ([\"acts'\", 'british']) / Label: 1\n",
      "Input: [24646, 1578] ([\"acts'\", 'chances']) / Label: 1\n",
      "Input: [1578, 24646] (['chances', \"acts'\"]) / Label: 1\n",
      "Input: [1578, 3] (['chances', 'of']) / Label: 1\n",
      "Input: [3, 1578] (['of', 'chances']) / Label: 1\n",
      "Input: [3, 10641] (['of', 'succeeding']) / Label: 1\n",
      "Input: [10641, 3] (['succeeding', 'of']) / Label: 1\n",
      "Input: [3850, 13056] (['regulations', 'cancellations']) / Label: 0\n",
      "Input: [1235, 23924] (['red', 'interacting']) / Label: 0\n",
      "Input: [1578, 37201] (['chances', 'season.having']) / Label: 0\n",
      "Input: [24646, 41898] ([\"acts'\", 'scurrilous']) / Label: 0\n",
      "Input: [880, 44714] (['groups', 'restlessness.']) / Label: 0\n",
      "Input: [160, 4758] (['british', 'interest.']) / Label: 0\n",
      "Input: [3, 3004] (['of', 'document']) / Label: 0\n",
      "Input: [24645, 7825] (['hindering', 'goode']) / Label: 0\n",
      "Input: [2, 41093] (['to', 'fanfare.']) / Label: 0\n",
      "Input: [1578, 18684] (['chances', 'recouped']) / Label: 0\n",
      "Input: [48, 34869] (['us', \"sebastian.real's\"]) / Label: 0\n",
      "Input: [160, 21429] (['british', 'regrets.']) / Label: 0\n",
      "Input: [3850, 19733] (['regulations', 'bubble.']) / Label: 0\n",
      "Input: [1309, 35894] (['tackle', 'dominici.']) / Label: 0\n",
      "Input: [2826, 8443] (['musicians', 'environments']) / Label: 0\n",
      "Input: [23, 39042] (['are', 'mcgeough']) / Label: 0\n",
      "Input: [2141, 14335] (['blamed', 'obstacles']) / Label: 0\n",
      "Input: [24646, 13087] ([\"acts'\", 'gasoline']) / Label: 0\n",
      "Input: [10641, 6492] (['succeeding', 'asked.']) / Label: 0\n",
      "Input: [34, 32620] (['which', 'ifzal']) / Label: 0\n",
      "Input: [7, 25550] (['for', 'valery']) / Label: 0\n",
      "Input: [48, 11165] (['us', 'lightbody']) / Label: 0\n",
      "Input: [2, 33787] (['to', 'orderboeing']) / Label: 0\n",
      "Input: [23, 9207] (['are', 'peugeot']) / Label: 0\n",
      "Input: [2755, 24603] (['visa', 'survey.a']) / Label: 0\n",
      "Input: [24644, 36361] ([\"tapemusicians'\", 'betray']) / Label: 0\n",
      "Input: [34, 14724] (['which', 'relocate']) / Label: 0\n",
      "Input: [23, 920] (['are', 'finance']) / Label: 0\n",
      "Input: [48, 39748] (['us', 'rhetorical']) / Label: 0\n",
      "Input: [2755, 28440] (['visa', 'headliners.']) / Label: 0\n",
      "Input: [1309, 7632] (['tackle', 'ilo']) / Label: 0\n",
      "Input: [23, 40788] (['are', \"sps's\"]) / Label: 0\n",
      "Input: [1309, 14121] (['tackle', 'worm.']) / Label: 0\n",
      "Input: [1309, 11120] (['tackle', 'preferring']) / Label: 0\n",
      "Input: [880, 22020] (['groups', 'casts']) / Label: 0\n",
      "Input: [48, 14449] (['us', 'neighbour.']) / Label: 0\n",
      "Input: [2, 6592] (['to', '4.7']) / Label: 0\n",
      "Input: [3, 13594] (['of', 'kp']) / Label: 0\n",
      "Input: [24645, 25344] (['hindering', \"tv'ronnie\"]) / Label: 0\n",
      "Input: [2141, 14649] (['blamed', 'holocaust.']) / Label: 0\n",
      "Input: [24644, 764] ([\"tapemusicians'\", \"country's\"]) / Label: 0\n",
      "Input: [1235, 35829] (['red', 'australia.rumours']) / Label: 0\n",
      "Input: [2, 16700] (['to', 'greet']) / Label: 0\n",
      "Input: [7, 34012] (['for', 'unearned']) / Label: 0\n",
      "Input: [3850, 31071] (['regulations', 'badged']) / Label: 0\n",
      "Input: [1235, 41233] (['red', 'enacted.']) / Label: 0\n",
      "Input: [1578, 46392] (['chances', 'humans.']) / Label: 0\n",
      "Input: [24646, 4085] ([\"acts'\", '42']) / Label: 0\n",
      "Input: [880, 19589] (['groups', 'brewers']) / Label: 0\n",
      "Input: [160, 2745] (['british', 'sought']) / Label: 0\n",
      "Input: [3, 21280] (['of', 'undeniable']) / Label: 0\n",
      "Input: [24645, 109] (['hindering', 'any']) / Label: 0\n",
      "Input: [2, 8174] (['to', 'injured.']) / Label: 0\n",
      "Input: [1578, 41591] (['chances', 'kenyaan']) / Label: 0\n",
      "Input: [48, 15531] (['us', \"panel's\"]) / Label: 0\n",
      "Input: [160, 40451] (['british', '.david']) / Label: 0\n",
      "Input: [3850, 2285] (['regulations', 'freedom']) / Label: 0\n",
      "Input: [1309, 45037] (['tackle', 'firewall.']) / Label: 0\n",
      "Input: [2826, 38897] (['musicians', 'elloway']) / Label: 0\n",
      "Input: [23, 8874] (['are', 'roof']) / Label: 0\n",
      "Input: [2141, 16685] (['blamed', \"bates'\"]) / Label: 0\n",
      "Input: [24646, 1135] ([\"acts'\", 'critics']) / Label: 0\n",
      "Input: [10641, 6258] (['succeeding', 'flawed']) / Label: 0\n",
      "Input: [34, 46194] (['which', 'promotions.anyone']) / Label: 0\n",
      "Input: [7, 11183] (['for', \"'a'\"]) / Label: 0\n",
      "Input: [48, 19378] (['us', 'rigging.']) / Label: 0\n",
      "Input: [2, 14633] (['to', 'professionally']) / Label: 0\n",
      "Input: [23, 47150] (['are', '61km']) / Label: 0\n",
      "Input: [2755, 3042] (['visa', '3d']) / Label: 0\n",
      "Input: [24644, 7021] ([\"tapemusicians'\", 'tone']) / Label: 0\n",
      "Input: [34, 18533] (['which', 'bishop.']) / Label: 0\n",
      "Input: [23, 23393] (['are', \"mini'apple\"]) / Label: 0\n",
      "Input: [48, 44011] (['us', 'livio']) / Label: 0\n",
      "Input: [2755, 35505] (['visa', 'deputised']) / Label: 0\n",
      "Input: [1309, 23631] (['tackle', 'amazing.']) / Label: 0\n",
      "Input: [23, 27128] (['are', 'missed.very']) / Label: 0\n",
      "Input: [1309, 7511] (['tackle', 'acted']) / Label: 0\n",
      "Input: [1309, 7852] (['tackle', \"dallaglio's\"]) / Label: 0\n",
      "Input: [880, 23166] (['groups', 'geographic']) / Label: 0\n",
      "Input: [48, 19264] (['us', '48m']) / Label: 0\n",
      "Input: [2, 27729] (['to', 'series.about']) / Label: 0\n",
      "Input: [3, 18553] (['of', 'footage.']) / Label: 0\n",
      "Input: [24645, 23111] (['hindering', 'lifethe']) / Label: 0\n",
      "Input: [2141, 22825] (['blamed', 'unenforceable']) / Label: 0\n",
      "Input: [24644, 9602] ([\"tapemusicians'\", 'incorporates']) / Label: 0\n",
      "Input: [1235, 9197] (['red', 'â£6']) / Label: 0\n",
      "Input: [2, 2774] (['to', 'publish']) / Label: 0\n",
      "Input: [7, 40183] (['for', 'tees']) / Label: 0\n",
      "Input: [3850, 12296] (['regulations', 'fools']) / Label: 0\n",
      "Input: [1235, 13878] (['red', 'manifestos.']) / Label: 0\n",
      "Input: [1578, 40330] (['chances', 'raid']) / Label: 0\n",
      "Input: [24646, 46884] ([\"acts'\", 'minimixa']) / Label: 0\n",
      "Input: [880, 10535] (['groups', 'napier']) / Label: 0\n",
      "Input: [160, 29717] (['british', 'â£352m']) / Label: 0\n",
      "Input: [3, 38567] (['of', 'shortstop']) / Label: 0\n",
      "Input: [24645, 17515] (['hindering', 'â£5.9m']) / Label: 0\n",
      "Input: [2, 24703] (['to', 'bouncers']) / Label: 0\n",
      "Input: [1578, 22402] (['chances', 'discredit']) / Label: 0\n",
      "Input: [48, 6715] (['us', 'mauresmo']) / Label: 0\n",
      "Input: [160, 38157] (['british', 'examines']) / Label: 0\n",
      "Input: [3850, 8917] (['regulations', 'objective']) / Label: 0\n",
      "Input: [1309, 40991] (['tackle', 'patrolling']) / Label: 0\n",
      "Input: [2826, 24082] (['musicians', 'exeem.']) / Label: 0\n",
      "Input: [23, 8279] (['are', \"lanka's\"]) / Label: 0\n",
      "Input: [2141, 43320] (['blamed', 'roundly']) / Label: 0\n",
      "Input: [24646, 37085] ([\"acts'\", 'hurdlerclocked']) / Label: 0\n",
      "Input: [10641, 33072] (['succeeding', '29bn']) / Label: 0\n",
      "Input: [34, 23353] (['which', \"symbian's\"]) / Label: 0\n",
      "Input: [7, 2313] (['for', 'fixed']) / Label: 0\n",
      "Input: [48, 27122] (['us', 'said.rob']) / Label: 0\n",
      "Input: [2, 44447] (['to', \"electronics'\"]) / Label: 0\n",
      "Input: [23, 21237] (['are', 'upright.']) / Label: 0\n",
      "Input: [2755, 12935] (['visa', 'bidders']) / Label: 0\n",
      "Input: [24644, 46297] ([\"tapemusicians'\", 'inconvenient']) / Label: 0\n",
      "Input: [34, 31698] (['which', \"beirut's\"]) / Label: 0\n",
      "Input: [23, 6617] (['are', 'arabia']) / Label: 0\n",
      "Input: [48, 44776] (['us', 'adrenaline']) / Label: 0\n",
      "Input: [2755, 31801] (['visa', 'signifies']) / Label: 0\n",
      "Input: [1309, 741] (['tackle', 'official']) / Label: 0\n",
      "Input: [23, 723] (['are', 'sunday']) / Label: 0\n",
      "Input: [1309, 7113] (['tackle', 'bubble']) / Label: 0\n",
      "Input: [1309, 11652] (['tackle', 'nicholls']) / Label: 0\n",
      "Input: [880, 29589] (['groups', '214.6bn']) / Label: 0\n",
      "Input: [48, 43879] (['us', \"'go\"]) / Label: 0\n",
      "Input: [2, 44369] (['to', 'analyze']) / Label: 0\n",
      "Input: [3, 32285] (['of', 'exporter.']) / Label: 0\n",
      "Input: [24645, 31731] (['hindering', 'bailouts.']) / Label: 0\n",
      "Input: [2141, 20887] (['blamed', 'dane']) / Label: 0\n",
      "Input: [24644, 19622] ([\"tapemusicians'\", 'disappointments']) / Label: 0\n",
      "Input: [1235, 40851] (['red', 'second.in']) / Label: 0\n",
      "Input: [2, 37740] (['to', 'debuts.']) / Label: 0\n",
      "Input: [7, 12143] (['for', 'doomed']) / Label: 0\n",
      "Input: [3850, 44988] (['regulations', 'world.cepes']) / Label: 0\n",
      "Input: [1235, 16907] (['red', 'solana']) / Label: 0\n",
      "Input: [1578, 9520] (['chances', \"toshiba's\"]) / Label: 0\n",
      "Input: [24646, 2996] ([\"acts'\", 'da']) / Label: 0\n",
      "Input: [880, 6321] (['groups', 'ministerial']) / Label: 0\n",
      "Input: [160, 26798] (['british', 'shawshank']) / Label: 0\n",
      "Input: [3, 28682] (['of', 'outdoors']) / Label: 0\n",
      "Input: [24645, 6153] (['hindering', 'chest']) / Label: 0\n",
      "Input: [2, 31086] (['to', 'favouring']) / Label: 0\n",
      "Input: [1578, 41095] (['chances', 'dems.city']) / Label: 0\n",
      "Input: [48, 42510] (['us', 'nastiest']) / Label: 0\n",
      "Input: [160, 11413] (['british', 'governmental']) / Label: 0\n",
      "Input: [3850, 40518] (['regulations', 'votestudents']) / Label: 0\n",
      "Input: [1309, 41725] (['tackle', 'mps.there']) / Label: 0\n",
      "Input: [2826, 12925] (['musicians', '120m']) / Label: 0\n",
      "Input: [23, 21779] (['are', 'win.the']) / Label: 0\n",
      "Input: [2141, 8946] (['blamed', 'myself.']) / Label: 0\n",
      "Input: [24646, 12719] ([\"acts'\", 'dissent']) / Label: 0\n",
      "Input: [10641, 14345] (['succeeding', 'diva']) / Label: 0\n",
      "Input: [34, 6168] (['which', 'halfway']) / Label: 0\n",
      "Input: [7, 8530] (['for', 'toure']) / Label: 0\n",
      "Input: [48, 1593] (['us', 'develop']) / Label: 0\n",
      "Input: [2, 27707] (['to', 'ho']) / Label: 0\n",
      "Input: [23, 26868] (['are', 'dominica']) / Label: 0\n",
      "Input: [2755, 19856] (['visa', 'inequality']) / Label: 0\n",
      "Input: [24644, 31705] ([\"tapemusicians'\", \"brewers'\"]) / Label: 0\n",
      "Input: [34, 34173] (['which', 'fargo.']) / Label: 0\n",
      "Input: [23, 2368] (['are', 'partly']) / Label: 0\n",
      "Input: [48, 4108] (['us', 'midfield']) / Label: 0\n",
      "Input: [2755, 17246] (['visa', 'explorer.']) / Label: 0\n",
      "Input: [1309, 43834] (['tackle', 'tastes.']) / Label: 0\n",
      "Input: [23, 30318] (['are', 'shochu']) / Label: 0\n",
      "Input: [1309, 11116] (['tackle', 'innocent.']) / Label: 0\n",
      "Input: [1309, 30209] (['tackle', 'carrick']) / Label: 0\n",
      "Input: [880, 9885] (['groups', \"'look\"]) / Label: 0\n",
      "Input: [48, 30706] (['us', 'planesair']) / Label: 0\n",
      "Input: [2, 17701] (['to', 'impractical']) / Label: 0\n",
      "Input: [3, 5831] (['of', 'produces']) / Label: 0\n",
      "Input: [24645, 46106] (['hindering', 'accesses']) / Label: 0\n",
      "Input: [2141, 30848] (['blamed', 'differential']) / Label: 0\n",
      "Input: [24644, 10941] ([\"tapemusicians'\", 'meaningful']) / Label: 0\n",
      "Input: [1235, 21641] (['red', 'inkling']) / Label: 0\n",
      "Input: [2, 20846] (['to', 'barton']) / Label: 0\n",
      "Input: [7, 15038] (['for', 'whittled']) / Label: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def cbow_grams(sequence, vocabulary_size, window_size = 4, negative_samples = 1., shuffle = True, categorical = False, sampling_table = None, seed = None):\n",
    "\n",
    "    targets, contexts, labels = [], [], []\n",
    "\n",
    "    for i, wi in enumerate(sequence):\n",
    "\n",
    "\n",
    "        if not wi or i < window_size or i + 1 > len(sequence) - window_size:\n",
    "            continue\n",
    "        if sampling_table is not None:\n",
    "            if sampling_table[wi] < random.random():\n",
    "                continue\n",
    "        \n",
    "        window_start = max(0, i - window_size)\n",
    "        window_end = min(len(sequence), i + window_size + 1)\n",
    "\n",
    "        context_words = [ wj for j, wj in enumerate(sequence[window_start:window_end])  if j+window_start != i]\n",
    "        target_word = wi\n",
    "\n",
    "        context_classes = tf.expand_dims(tf.constant(context_words, dtype = 'int64'), 0)\n",
    "\n",
    "        negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "            true_classes= context_classes,\n",
    "            num_true= window_size * 2,\n",
    "            num_sampled = negative_samples,\n",
    "            unique = True,\n",
    "            range_max = vocabulary_size,\n",
    "            name = 'negative_sampling'\n",
    "        )\n",
    "\n",
    "        #build context and label vectors\n",
    "        negative_targets = negative_sampling_candidates.numpy().tolist()\n",
    "\n",
    "        target = [target_word] + negative_targets\n",
    "        label = [1] + [0]*negative_samples\n",
    "\n",
    "        #Append each element from the training example to global list\n",
    "        targets.extend(target)\n",
    "        contexts.extend([context_words]*(negative_samples+1))\n",
    "        labels.extend(label)\n",
    "\n",
    "    couples = list(zip(targets, contexts))\n",
    "\n",
    "    seed = random.randint(0, 10e6)\n",
    "    random.seed(seed)\n",
    "    random.shuffle(couples)\n",
    "    random.seed(seed)\n",
    "    random.shuffle(labels)\n",
    "\n",
    "    return couples, labels\n",
    "\n",
    "window_size = 1 # How many words to consider left and right\n",
    "\n",
    "inputs, labels = cbow_grams(\n",
    "    tokenizer.texts_to_sequences([\"i am going to the store\"])[0],\n",
    "    vocabulary_size = len(tokenizer.word_index.items()) + 1,\n",
    "    window_size= window_size, negative_samples=4, shuffle = False,\n",
    "    categorical = False,\n",
    "    sampling_table= None,\n",
    "    seed = None\n",
    ")\n",
    "\n",
    "window_size = 1 # How many words to consider left and right.\n",
    "\n",
    "inputs, labels = tf.keras.preprocessing.sequence.skipgrams(\n",
    "    tokenizer.texts_to_sequences([news_stories[0][:150]])[0], \n",
    "    vocabulary_size=len(tokenizer.word_index.items())+1, \n",
    "    window_size=window_size, negative_samples=4, shuffle=False,\n",
    "    categorical=False, sampling_table=None, seed=None\n",
    ")\n",
    "\n",
    "i = 0\n",
    "for inp, lbl in zip(inputs, labels):\n",
    "    i += 1\n",
    "    print(f\"Input: {inp} ({[tokenizer.index_word[wi] for wi in inp]}) / Label: {lbl}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [2826, 2] (['musicians', 'to']) / Label: 1\n",
      "Input: [2, 2826] (['to', 'musicians']) / Label: 1\n",
      "Input: [2, 1309] (['to', 'tackle']) / Label: 1\n",
      "Input: [1309, 2] (['tackle', 'to']) / Label: 1\n",
      "Input: [1309, 48] (['tackle', 'us']) / Label: 1\n",
      "Input: [48, 1309] (['us', 'tackle']) / Label: 1\n",
      "Input: [48, 1235] (['us', 'red']) / Label: 1\n",
      "Input: [1235, 48] (['red', 'us']) / Label: 1\n",
      "Input: [1235, 24644] (['red', \"tapemusicians'\"]) / Label: 1\n",
      "Input: [24644, 1235] ([\"tapemusicians'\", 'red']) / Label: 1\n",
      "Input: [24644, 880] ([\"tapemusicians'\", 'groups']) / Label: 1\n",
      "Input: [880, 24644] (['groups', \"tapemusicians'\"]) / Label: 1\n",
      "Input: [880, 23] (['groups', 'are']) / Label: 1\n",
      "Input: [23, 880] (['are', 'groups']) / Label: 1\n",
      "Input: [23, 2] (['are', 'to']) / Label: 1\n",
      "Input: [2, 23] (['to', 'are']) / Label: 1\n",
      "Input: [2, 1309] (['to', 'tackle']) / Label: 1\n",
      "Input: [1309, 2] (['tackle', 'to']) / Label: 1\n",
      "Input: [1309, 48] (['tackle', 'us']) / Label: 1\n",
      "Input: [48, 1309] (['us', 'tackle']) / Label: 1\n",
      "Input: [48, 2755] (['us', 'visa']) / Label: 1\n",
      "Input: [2755, 48] (['visa', 'us']) / Label: 1\n",
      "Input: [2755, 3850] (['visa', 'regulations']) / Label: 1\n",
      "Input: [3850, 2755] (['regulations', 'visa']) / Label: 1\n",
      "Input: [3850, 34] (['regulations', 'which']) / Label: 1\n",
      "Input: [34, 3850] (['which', 'regulations']) / Label: 1\n",
      "Input: [34, 23] (['which', 'are']) / Label: 1\n",
      "Input: [23, 34] (['are', 'which']) / Label: 1\n",
      "Input: [23, 2141] (['are', 'blamed']) / Label: 1\n",
      "Input: [2141, 23] (['blamed', 'are']) / Label: 1\n",
      "Input: [2141, 7] (['blamed', 'for']) / Label: 1\n",
      "Input: [7, 2141] (['for', 'blamed']) / Label: 1\n",
      "Input: [7, 24645] (['for', 'hindering']) / Label: 1\n",
      "Input: [24645, 7] (['hindering', 'for']) / Label: 1\n",
      "Input: [24645, 160] (['hindering', 'british']) / Label: 1\n",
      "Input: [160, 24645] (['british', 'hindering']) / Label: 1\n",
      "Input: [160, 24646] (['british', \"acts'\"]) / Label: 1\n",
      "Input: [24646, 160] ([\"acts'\", 'british']) / Label: 1\n",
      "Input: [24646, 1578] ([\"acts'\", 'chances']) / Label: 1\n",
      "Input: [1578, 24646] (['chances', \"acts'\"]) / Label: 1\n",
      "Input: [1578, 3] (['chances', 'of']) / Label: 1\n",
      "Input: [3, 1578] (['of', 'chances']) / Label: 1\n",
      "Input: [3, 10641] (['of', 'succeeding']) / Label: 1\n",
      "Input: [10641, 3] (['succeeding', 'of']) / Label: 1\n",
      "Input: [7, 37372] (['for', 'persieashley']) / Label: 0\n",
      "Input: [48, 16081] (['us', 'politically.']) / Label: 0\n",
      "Input: [23, 6436] (['are', 'crashed']) / Label: 0\n",
      "Input: [23, 42180] (['are', 'pounds.']) / Label: 0\n",
      "Input: [2141, 4526] (['blamed', 'updated']) / Label: 0\n",
      "Input: [3, 46107] (['of', 'cautioned.']) / Label: 0\n",
      "Input: [24645, 34018] (['hindering', 'ministries.']) / Label: 0\n",
      "Input: [1235, 24164] (['red', \"'greatest\"]) / Label: 0\n",
      "Input: [23, 17634] (['are', 'jerwood']) / Label: 0\n",
      "Input: [880, 25718] (['groups', 'prize.doris']) / Label: 0\n",
      "Input: [48, 37581] (['us', 'thokozani']) / Label: 0\n",
      "Input: [880, 3216] (['groups', 'launching']) / Label: 0\n",
      "Input: [24644, 21717] ([\"tapemusicians'\", 'resolved.']) / Label: 0\n",
      "Input: [1309, 39472] (['tackle', 'crackled']) / Label: 0\n",
      "Input: [2, 46714] (['to', 'diverse.']) / Label: 0\n",
      "Input: [3850, 23469] (['regulations', 'confusingly']) / Label: 0\n",
      "Input: [7, 1057] (['for', 'send']) / Label: 0\n",
      "Input: [2, 1924] (['to', 'introduce']) / Label: 0\n",
      "Input: [2755, 11071] (['visa', 'pregnant']) / Label: 0\n",
      "Input: [24646, 23971] ([\"acts'\", 'materialists']) / Label: 0\n",
      "Input: [24646, 43284] ([\"acts'\", \"war.i'd\"]) / Label: 0\n",
      "Input: [10641, 22589] (['succeeding', 'struck.']) / Label: 0\n",
      "Input: [3, 24737] (['of', 'deadlinesinger']) / Label: 0\n",
      "Input: [2826, 23086] (['musicians', 'bolz']) / Label: 0\n",
      "Input: [2, 27158] (['to', 'bondy']) / Label: 0\n",
      "Input: [2755, 15412] (['visa', 'calyon']) / Label: 0\n",
      "Input: [24644, 10666] ([\"tapemusicians'\", '18m']) / Label: 0\n",
      "Input: [34, 23990] (['which', 'beefing']) / Label: 0\n",
      "Input: [48, 33982] (['us', 'reutersrevenues']) / Label: 0\n",
      "Input: [1578, 8073] (['chances', 'revival.']) / Label: 0\n",
      "Input: [24645, 22734] (['hindering', 'cornerstone']) / Label: 0\n",
      "Input: [1235, 24844] (['red', \"'rape'us\"]) / Label: 0\n",
      "Input: [23, 36279] (['are', 'yesterday.']) / Label: 0\n",
      "Input: [160, 13372] (['british', 'settlements']) / Label: 0\n",
      "Input: [1309, 27473] (['tackle', 'nostalgia.']) / Label: 0\n",
      "Input: [1309, 24764] (['tackle', 'chili']) / Label: 0\n",
      "Input: [34, 33487] (['which', 'citu']) / Label: 0\n",
      "Input: [3850, 26695] (['regulations', 'headache.']) / Label: 0\n",
      "Input: [1309, 22841] (['tackle', 'blair.he']) / Label: 0\n",
      "Input: [2141, 14709] (['blamed', 'afghanistan.']) / Label: 0\n",
      "Input: [2, 7584] (['to', 'context.']) / Label: 0\n",
      "Input: [1578, 7835] (['chances', 'llanelli']) / Label: 0\n",
      "Input: [48, 40940] (['us', 'heartened']) / Label: 0\n",
      "Input: [160, 9080] (['british', 'provinces']) / Label: 0\n",
      "Input: [7, 1111] (['for', 'pair']) / Label: 0\n",
      "Input: [48, 26931] (['us', 'royce.']) / Label: 0\n",
      "Input: [23, 37606] (['are', 'parkes']) / Label: 0\n",
      "Input: [23, 3855] (['are', 'schemes']) / Label: 0\n",
      "Input: [2141, 14278] (['blamed', 'blades']) / Label: 0\n",
      "Input: [3, 37450] (['of', 'night.a']) / Label: 0\n",
      "Input: [24645, 36343] (['hindering', '117th']) / Label: 0\n",
      "Input: [1235, 38629] (['red', 'baldini']) / Label: 0\n",
      "Input: [23, 41556] (['are', 'tories.it']) / Label: 0\n",
      "Input: [880, 2223] (['groups', 'trillion']) / Label: 0\n",
      "Input: [48, 9073] (['us', 'scandals']) / Label: 0\n",
      "Input: [880, 38849] (['groups', 'harried']) / Label: 0\n",
      "Input: [24644, 45867] ([\"tapemusicians'\", 'excused']) / Label: 0\n",
      "Input: [1309, 39242] (['tackle', 'mass.']) / Label: 0\n",
      "Input: [2, 19574] (['to', 'rowa']) / Label: 0\n",
      "Input: [3850, 21078] (['regulations', 'lualua']) / Label: 0\n",
      "Input: [7, 2720] (['for', 'professor']) / Label: 0\n",
      "Input: [2, 30238] (['to', 'â£227bn']) / Label: 0\n",
      "Input: [2755, 37282] (['visa', 'map.']) / Label: 0\n",
      "Input: [24646, 13999] ([\"acts'\", 'truants']) / Label: 0\n",
      "Input: [24646, 33352] ([\"acts'\", '.yesterday']) / Label: 0\n",
      "Input: [10641, 38769] (['succeeding', 'murrayfield.that']) / Label: 0\n",
      "Input: [3, 20941] (['of', 'challengers']) / Label: 0\n",
      "Input: [2826, 21250] (['musicians', 'robinsonengland']) / Label: 0\n",
      "Input: [2, 26877] (['to', 'doorway.']) / Label: 0\n",
      "Input: [2755, 3741] (['visa', '20th']) / Label: 0\n",
      "Input: [24644, 21151] ([\"tapemusicians'\", 'snaffled']) / Label: 0\n",
      "Input: [34, 16863] (['which', 'incapacity']) / Label: 0\n",
      "Input: [48, 19819] (['us', 'gt']) / Label: 0\n",
      "Input: [1578, 23679] (['chances', 'cranked']) / Label: 0\n",
      "Input: [24645, 7823] (['hindering', 'courtesy']) / Label: 0\n",
      "Input: [1235, 34814] (['red', 'friendly.']) / Label: 0\n",
      "Input: [23, 28022] (['are', 'goth']) / Label: 0\n",
      "Input: [160, 33973] (['british', 'burgundy']) / Label: 0\n",
      "Input: [1309, 14820] (['tackle', 'settles']) / Label: 0\n",
      "Input: [1309, 8735] (['tackle', 'contentious']) / Label: 0\n",
      "Input: [34, 23207] (['which', 'exhibit']) / Label: 0\n",
      "Input: [3850, 36998] (['regulations', 'rotherham']) / Label: 0\n",
      "Input: [1309, 11915] (['tackle', 'bureaucratic']) / Label: 0\n",
      "Input: [2141, 25154] (['blamed', 'adarsh.kisna']) / Label: 0\n",
      "Input: [2, 12840] (['to', 'geldof']) / Label: 0\n",
      "Input: [1578, 28905] (['chances', 'masahiro']) / Label: 0\n",
      "Input: [48, 47120] (['us', 'acute']) / Label: 0\n",
      "Input: [160, 663] (['british', 'shows']) / Label: 0\n",
      "Input: [7, 25406] (['for', \"want'.\"]) / Label: 0\n",
      "Input: [48, 19331] (['us', 'literate']) / Label: 0\n",
      "Input: [23, 8206] (['are', 'guarantees']) / Label: 0\n",
      "Input: [23, 3376] (['are', 'acquisition']) / Label: 0\n",
      "Input: [2141, 32347] (['blamed', '1945.']) / Label: 0\n",
      "Input: [3, 34128] (['of', 'said.union']) / Label: 0\n",
      "Input: [24645, 11768] (['hindering', 'campbell.']) / Label: 0\n",
      "Input: [1235, 28841] (['red', 'feud.50']) / Label: 0\n",
      "Input: [23, 44917] (['are', 'adsmusic']) / Label: 0\n",
      "Input: [880, 6041] (['groups', 'incorporated']) / Label: 0\n",
      "Input: [48, 43339] (['us', 'paranoia']) / Label: 0\n",
      "Input: [880, 41106] (['groups', 'for.people']) / Label: 0\n",
      "Input: [24644, 20670] ([\"tapemusicians'\", 'remarkably']) / Label: 0\n",
      "Input: [1309, 10535] (['tackle', 'napier']) / Label: 0\n",
      "Input: [2, 5134] (['to', 'appeal.']) / Label: 0\n",
      "Input: [3850, 4551] (['regulations', 'announcing']) / Label: 0\n",
      "Input: [7, 40299] (['for', 'possibilty']) / Label: 0\n",
      "Input: [2, 2267] (['to', 'worldcom']) / Label: 0\n",
      "Input: [2755, 40462] (['visa', 'mazen']) / Label: 0\n",
      "Input: [24646, 17877] ([\"acts'\", 'takingsoscar']) / Label: 0\n",
      "Input: [24646, 31913] ([\"acts'\", \"eco's\"]) / Label: 0\n",
      "Input: [10641, 43760] (['succeeding', 'â£68']) / Label: 0\n",
      "Input: [3, 40767] (['of', 'ochil']) / Label: 0\n",
      "Input: [2826, 19455] (['musicians', 'respite']) / Label: 0\n",
      "Input: [2, 27706] (['to', 'tele']) / Label: 0\n",
      "Input: [2755, 45078] (['visa', \"bloom's\"]) / Label: 0\n",
      "Input: [24644, 44660] ([\"tapemusicians'\", 'coppin.']) / Label: 0\n",
      "Input: [34, 23900] (['which', 'lucas.']) / Label: 0\n",
      "Input: [48, 31753] (['us', 'intercity']) / Label: 0\n",
      "Input: [1578, 46272] (['chances', 'rental.']) / Label: 0\n",
      "Input: [24645, 43650] (['hindering', \"works.it's\"]) / Label: 0\n",
      "Input: [1235, 1226] (['red', 'field']) / Label: 0\n",
      "Input: [23, 35597] (['are', 'magne']) / Label: 0\n",
      "Input: [160, 7030] (['british', 'newton']) / Label: 0\n",
      "Input: [1309, 31248] (['tackle', 'chains.']) / Label: 0\n",
      "Input: [1309, 18386] (['tackle', 'overwhelming.']) / Label: 0\n",
      "Input: [34, 38453] (['which', 'nirupama']) / Label: 0\n",
      "Input: [3850, 35793] (['regulations', 'yards.arsenal']) / Label: 0\n",
      "Input: [1309, 41003] (['tackle', 'invoking']) / Label: 0\n",
      "Input: [2141, 34575] (['blamed', 'responsible.one']) / Label: 0\n",
      "Input: [2, 34218] (['to', 'â£32.26.why']) / Label: 0\n",
      "Input: [1578, 2038] (['chances', 'usually']) / Label: 0\n",
      "Input: [48, 9465] (['us', 'addictive']) / Label: 0\n",
      "Input: [160, 36884] (['british', 'salient']) / Label: 0\n",
      "Input: [7, 28564] (['for', 'haydn']) / Label: 0\n",
      "Input: [48, 11023] (['us', 'rest.']) / Label: 0\n",
      "Input: [23, 517] (['are', 'asked']) / Label: 0\n",
      "Input: [23, 24745] (['are', 'crowncomedy']) / Label: 0\n",
      "Input: [2141, 21095] (['blamed', 'infection.']) / Label: 0\n",
      "Input: [3, 3833] (['of', 'wto']) / Label: 0\n",
      "Input: [24645, 16211] (['hindering', 'dominating']) / Label: 0\n",
      "Input: [1235, 45040] (['red', 'purchaser']) / Label: 0\n",
      "Input: [23, 46662] (['are', 'customers.people']) / Label: 0\n",
      "Input: [880, 36847] (['groups', 'substitution']) / Label: 0\n",
      "Input: [48, 23967] (['us', 'bjorn.']) / Label: 0\n",
      "Input: [880, 4328] (['groups', 'guitarist']) / Label: 0\n",
      "Input: [24644, 11877] ([\"tapemusicians'\", 'skip']) / Label: 0\n",
      "Input: [1309, 14330] (['tackle', 'otis']) / Label: 0\n",
      "Input: [2, 19466] (['to', 'naris']) / Label: 0\n",
      "Input: [3850, 33833] (['regulations', 'â£775']) / Label: 0\n",
      "Input: [7, 19322] (['for', 'totalthe']) / Label: 0\n",
      "Input: [2, 37883] (['to', 'added.horak']) / Label: 0\n",
      "Input: [2755, 27792] (['visa', 'diesscreenwriter']) / Label: 0\n",
      "Input: [24646, 37028] ([\"acts'\", 'article.']) / Label: 0\n",
      "Input: [24646, 2443] ([\"acts'\", 'backs']) / Label: 0\n",
      "Input: [10641, 31154] (['succeeding', 'seifert.']) / Label: 0\n",
      "Input: [3, 16877] (['of', 'regiment.']) / Label: 0\n",
      "Input: [2826, 11371] (['musicians', 'simplify']) / Label: 0\n",
      "Input: [2, 9553] (['to', 'station.']) / Label: 0\n",
      "Input: [2755, 539] (['visa', 'buy']) / Label: 0\n",
      "Input: [24644, 13947] ([\"tapemusicians'\", 'hoon']) / Label: 0\n",
      "Input: [34, 36543] (['which', 'iterated']) / Label: 0\n",
      "Input: [48, 37268] (['us', 'me.purely']) / Label: 0\n",
      "Input: [1578, 6003] (['chances', 'barbara']) / Label: 0\n",
      "Input: [24645, 1455] (['hindering', 'july']) / Label: 0\n",
      "Input: [1235, 17081] (['red', 'hypnotism']) / Label: 0\n",
      "Input: [23, 31488] (['are', 'hannes']) / Label: 0\n",
      "Input: [160, 33725] (['british', 'uniformity']) / Label: 0\n",
      "Input: [1309, 24706] (['tackle', 'hotel.']) / Label: 0\n",
      "Input: [1309, 7167] (['tackle', 'examined']) / Label: 0\n",
      "Input: [34, 40677] (['which', \"amin's\"]) / Label: 0\n",
      "Input: [3850, 9762] (['regulations', 'embark']) / Label: 0\n",
      "Input: [1309, 37537] (['tackle', 'musselburgh']) / Label: 0\n",
      "Input: [2141, 28887] (['blamed', 'home.she']) / Label: 0\n",
      "Input: [2, 8968] (['to', 'massively']) / Label: 0\n",
      "Input: [1578, 13267] (['chances', 'relaxation']) / Label: 0\n",
      "Input: [48, 16673] (['us', 'staked']) / Label: 0\n",
      "Input: [160, 41927] (['british', 'folkes.']) / Label: 0\n"
     ]
    }
   ],
   "source": [
    "window_size = 1 # How many words to consider left and right.\n",
    "\n",
    "inputs, labels = tf.keras.preprocessing.sequence.skipgrams(\n",
    "    tokenizer.texts_to_sequences([news_stories[0][:150]])[0], \n",
    "    vocabulary_size=len(tokenizer.word_index.items())+1, \n",
    "    window_size=window_size, negative_samples=4, shuffle=False,\n",
    "    categorical=False, sampling_table=None, seed=None\n",
    ")\n",
    "\n",
    "i = 0\n",
    "for inp, lbl in zip(inputs, labels):\n",
    "    i += 1\n",
    "    print(f\"Input: {inp} ({[tokenizer.index_word[wi] for wi in inp]}) / Label: {lbl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4096 # Data points in a single batch\n",
    "\n",
    "embedding_size = 128 # Dimension of the embedding vector\n",
    "\n",
    "window_size = 1 # Using window size of 1 on either side of the target word\n",
    "epochs = 5 \n",
    "negative_samples = 4 # Number of negative samples generated per example\n",
    "\n",
    "#Picking a random validation set to sample nearest neighbors \n",
    "valid_size = 16 # Random set of words to evaluate similarity on.\n",
    "# We sample valid datapoints randomly from a large window without always being deterministic\n",
    "valid_window = 250\n",
    "\n",
    "# When selecting valid examples, we select some of the most frequent words as well as\n",
    "# some moderately rare words as well\n",
    "np.random.seed(54321)\n",
    "random.seed(54321)\n",
    "\n",
    "valid_term_ids = np.array(random.sample(range(valid_window), valid_size))\n",
    "valid_term_ids = np.append(\n",
    "    valid_term_ids, random.sample(range(1000, 1000+valid_window), valid_size),\n",
    "    axis=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 125,  200,   17,   62,   43,  141,  135,  100,   44,  234,   82,\n",
       "        131,  209,   72,  175,   30, 1007, 1194, 1073, 1114, 1006, 1019,\n",
       "       1169, 1029, 1132, 1154, 1049, 1199, 1180, 1053, 1008, 1113])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_term_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cbow_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " context_embedding (Embedding)  (None, 2, 128)       6039936     ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " target_embedding (Embedding)   (None, 128)          6039936     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 2)            0           ['context_embedding[0][0]',      \n",
      "                                                                  'target_embedding[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 12,079,872\n",
      "Trainable params: 12,079,872\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "\n",
    "# Inputs; target input layer will have the final shape [None]\n",
    "# context will have [None, 2xwindow_size] shape\n",
    "input_1 = tf.keras.layers.Input(shape=())\n",
    "input_2 = tf.keras.layers.Input(shape=(window_size*2,))\n",
    "\n",
    "# Target and context embedding layers\n",
    "target_embedding_layer = tf.keras.layers.Embedding(\n",
    "    input_dim=n_vocab, output_dim=embedding_size, name='target_embedding'\n",
    ")\n",
    "\n",
    "context_embedding_layer = tf.keras.layers.Embedding(\n",
    "    input_dim=n_vocab, output_dim=embedding_size, name='context_embedding'\n",
    ")\n",
    "\n",
    "# Outputs of the target and context embedding lookups\n",
    "context_out = context_embedding_layer(input_2)\n",
    "target_out = target_embedding_layer(input_1)\n",
    "\n",
    "# Taking the mean over the all the context words to produce [None, embedding_size]\n",
    "mean_context_out = tf.keras.layers.Lambda(lambda x: tf.reduce_mean(x, axis=1))(context_out)\n",
    "\n",
    "# Computing the dot product between the two \n",
    "out = tf.keras.layers.Dot(axes=-1)([context_out, target_out])\n",
    "\n",
    "cbow_model = tf.keras.models.Model(inputs=[input_1, input_2], outputs=out, name='cbow_model')\n",
    "\n",
    "cbow_model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), \n",
    "    optimizer='adam'\n",
    ")\n",
    "\n",
    "cbow_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(\n",
    "        n_vocab, sampling_factor = 1e-05\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cbow_data_generator(sequences, window_size, batch_size, negative_samples):\n",
    "    \n",
    "    rand_sequence_ids = np.arange(len(sequences))                    \n",
    "    np.random.shuffle(rand_sequence_ids)\n",
    "\n",
    "    for si in rand_sequence_ids:\n",
    "        inputs, labels = cbow_grams(\n",
    "            sequences[si], \n",
    "            vocabulary_size=n_vocab, \n",
    "            window_size=window_size, \n",
    "            negative_samples=negative_samples, \n",
    "            shuffle=True,\n",
    "            sampling_table=sampling_table,\n",
    "            seed=None\n",
    "        )\n",
    "        \n",
    "        inputs_context, inputs_target, labels = np.array([inp[1] for inp in inputs]), np.array([inp[0] for inp in inputs]), np.array(labels).reshape(-1,1)\n",
    "        \n",
    "        assert inputs_context.shape[0] == inputs_target.shape[0]\n",
    "        assert inputs_context.shape[0] == labels.shape[0]\n",
    "        \n",
    "        #print(inputs_context.shape, inputs_target.shape, labels.shape)\n",
    "        for eg_id_start in range(0, inputs_context.shape[0], batch_size):            \n",
    "            \n",
    "            yield (\n",
    "                inputs_target[eg_id_start: min(eg_id_start+batch_size, inputs_target.shape[0])], \n",
    "                inputs_context[eg_id_start: min(eg_id_start+batch_size, inputs_context.shape[0]),:]\n",
    "            ), labels[eg_id_start: min(eg_id_start+batch_size, labels.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the model and evaluating the model\n",
    "\n",
    "class ValidationCallback(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, valid_term_ids, model_with_embeddings, tokenizer):\n",
    "\n",
    "        self.valid_term_ids = valid_term_ids\n",
    "        self.model_with_embeddings = model_with_embeddings\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs = None):\n",
    "        \"\"\"Validation logic\"\"\"\n",
    "\n",
    "        #Using context embeddings to get the most similar \n",
    "        # Other strategies include: using target embeddings, mean embeddings after avaraging context/target\n",
    "\n",
    "        embedding_weights = self.model_with_embeddings.get_layer(\"context_embedding\").get_weights()[0]\n",
    "        normalized_embeddings = embedding_weights / np.sqrt(np.sum(embedding_weights**2, axis = 1, keepdims=True))\n",
    "\n",
    "        # Get the embeddings corresping to valid_term_ids \n",
    "        valid_embeddings = normalized_embeddings[self.valid_term_ids,:]\n",
    "\n",
    "        # Compute the similarity between valid_term_ids and all the embeddings\n",
    "        # V x d (d x D) => V x D\n",
    "        top_k = 5 # Top k items will be displayed\n",
    "        similarity = np.dot(valid_embeddings, normalized_embeddings.T)\n",
    "\n",
    "        # Invert similarity matrix to negative\n",
    "        # Ignore the first one because that would be the same word as the probe word\n",
    "        similarity_top_k = np.argsort(-similarity, axis=1)[:, 1: top_k+1]\n",
    "\n",
    "        #Print the output\n",
    "        for i, term_id in enumerate(valid_term_ids):\n",
    "\n",
    "            similar_word_str = ','.join([self.tokenizer.index_word[j] for j in similarity_top_k[i, :] if j > 1])\n",
    "            print(f\"{self.tokenizer.index_word[term_id]}): {similar_word_str}\")\n",
    "\n",
    "        print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5 started\n",
      "   2227/Unknown - 46s 20ms/step - loss: 0.4886labour): conservative,basic,banned,midfield,germany's\n",
      "based): meanwhile,documentary,chicago,capital,dan\n",
      "has): had,have,felt,david,scale\n",
      "you): format,association.,limited,daniel,actually\n",
      "also): democratic,honour,salary,wooden,deeply\n",
      "between): boyd,gmt,anderson,powers,prison\n",
      "go): won't,profit,criminal,alicia,hollywood\n",
      "film): micro,king,french,smaller,opening\n",
      "who): pressure,whereas,stuart,respect,legend\n",
      "another): near,department,easily,prior,federation\n",
      "make): memory,totally,honour,death,statement\n",
      "since): safety,euro,indeed,darren,nicolas\n",
      "me): anderson,kevin,injury,stadium,event\n",
      "so): absolutely,roy,believed,park,germany\n",
      "added): won't,king,gareth,expectations,andy\n",
      "mr): japan,charles,total,parent,star\n",
      "figure): veteran,anderson,hollywood,estimated,web\n",
      "roddick): physical,management,systems,television,johnson\n",
      "income): survey,including,reforms,gadget,budget\n",
      "wins): basis,carolina,machine,ronaldo,opera\n",
      "attempt): services.,physical,anderson,television,earnings\n",
      "that.): ordinary,production,basic,human,according\n",
      "wide): 1990s,your,bono,shaw,regulatory\n",
      "nominated): organic,management,bus,bob,intensive\n",
      "bankruptcy): ordinary,n,t,son,old.\n",
      "highest): lawyer,paris,estimated,china's,travel\n",
      "james): plus,kelly,prevent,gmt,nicolas\n",
      "separate): women's,voting,properly,prior,memory\n",
      "gadgets): nicolas,euros,sri,st,storage\n",
      "lives): gold,carolina,motorcycle,goalkeeper,death\n",
      "millions): banned,industrial,travel,insisted,ea\n",
      "confident): range,euros,performing,vast,faces\n",
      "\n",
      "\n",
      "2227/2227 [==============================] - 46s 21ms/step - loss: 0.4886\n",
      "Epoch: 2/5 started\n",
      "   2226/Unknown - 45s 20ms/step - loss: 0.4179labour): conservative,speculation,emerging,various,club's\n",
      "based): motor,humanitarian,'new,tunnel,newcomer\n",
      "has): had,have,dominated,already,recently\n",
      "you): we,they,don't,i,people\n",
      "also): been,never,what,already,being\n",
      "between): rates.,convertible,gameboy,sibierski,manic\n",
      "go): tindall,referee,â£11.7m,disguise,indeed\n",
      "film): europe's,uk's,glazer's,commerce,region\n",
      "who): expect,peter,o,replacing,warned\n",
      "another): dementieva,headlines,park.,theme,business.\n",
      "make): feel,johnson.,just,we're,appears\n",
      "since): 2003.,in.,june,grade,aged\n",
      "me): yourself,game's,additional,en,chambers\n",
      "so): too,humans,very,re,successes\n",
      "added): added.,said.,nick,gareth,daughter\n",
      "mr): tony,charles,gordon,told,silk\n",
      "figure): expressed,anne,somewhat,patrick,campaigns\n",
      "roddick): stuart,owner,olivier,boyd,son\n",
      "income): houllier,outfit,science,alcohol,manner\n",
      "wins): blears,harriet,carolina,walker,51\n",
      "attempt): herself,rallying,harman,secretly,hapless\n",
      "that.): sunderland,khatami,predictions,edu,merger\n",
      "wide): vast,edged,roughly,woodhill,us's\n",
      "nominated): susan,organic,entitled,35,prohibited\n",
      "bankruptcy): fought,paying,3.8,cvs,beijing\n",
      "highest): presidential,songwriter,enabling,hall,loose\n",
      "james): d,believes,m,boss,s\n",
      "separate): daughter,takenaka,promote,browsers,sex\n",
      "gadgets): max,bae,kenyan,sebastien,arrested\n",
      "lives): sebastien,carolina,barely,prince,stuart\n",
      "millions): stood,sutton,flight,anymore,comeback\n",
      "confident): vodafone,fred,wallace,gallery,pierre\n",
      "\n",
      "\n",
      "2227/2227 [==============================] - 45s 20ms/step - loss: 0.4179\n",
      "Epoch: 3/5 started\n",
      "   2226/Unknown - 42s 19ms/step - loss: 0.3884labour): speculation,mini,acting,purpose,various\n",
      "based): arizona.,identifies,regional,boundary,coal\n",
      "has): had,have,previously,repeatedly,i've\n",
      "you): we,they,i,don't,didn't\n",
      "also): already,been,never,reportedly,had\n",
      "between): ignite,worldwide.,rates.,finland,scoring\n",
      "go): give,happen,properly,play,disguise\n",
      "film): football,uk's,season's,fiction,purpose\n",
      "who): expect,moved,triumphed,kevin,warned\n",
      "another): theme,humans,206bn,experience,easing\n",
      "make): give,do,happen,never,let\n",
      "since): 2003,june,2004.,2003.,in\n",
      "me): him.,him,why,smoking,them\n",
      "so): very,too,firms.,really,how\n",
      "added): said.,added.,insisted,accused,says\n",
      "mr): tony,gordon,silk,charles,bernie\n",
      "figure): loan,enjoying,image,easing,danger\n",
      "roddick): goode,raymond,gomarsall,beattie,â£10\n",
      "income): alcohol,'blatant,pretenders,lagrimas,captaincy\n",
      "wins): met.,coordinator,simmons,hooker,pow\n",
      "attempt): 5m,h.,delightful,path,costello\n",
      "that.): sunderland,vulnerability.internet,edu,overlap,remy\n",
      "wide): bewildering,large,vast,fundamental,20's\n",
      "nominated): jake,tykes,â£25,whereas,newly\n",
      "bankruptcy): fought,bertelsmann's,moves,en,hat\n",
      "highest): donated,june's,salaries,oxley,massachusetts\n",
      "james): duncan,thompson,chris,johnson,m\n",
      "separate): frequencies,string,.subs,lacroix,generate\n",
      "gadgets): bases.,â£250,briefings,difficulties,nipple\n",
      "lives): sebastien,ukip's,sean,systems,kicker\n",
      "millions): maker's,fitzgerald.,en,magazines,themselves.\n",
      "confident): delighted,happen,disguise,stick,everybody\n",
      "\n",
      "\n",
      "2227/2227 [==============================] - 42s 19ms/step - loss: 0.3884\n",
      "Epoch: 4/5 started\n",
      "   2227/Unknown - 42s 19ms/step - loss: 0.3636labour): mini,conservative,speculation,conservatives,nowhere\n",
      "based): arizona.,regional,conservatory.,unpatched.,loser.\n",
      "has): had,repeatedly,have,developed.the,previously\n",
      "you): we,they,i,don't,why\n",
      "also): already,never,initially,reportedly,been\n",
      "between): unlawfully,scoring,5bn,compared,finland\n",
      "go): play,pixies,properly,afford,get\n",
      "film): honouractor,mgm,football,movie,glazer's\n",
      "who): triumphed,eventually,moved,roy,kevin\n",
      "another): break,humans,comeback,crash.,a\n",
      "make): give,do,apply,persuade,feel\n",
      "since): in,june,2003,2004.,17\n",
      "me): him,tories,certainly,why,this.\n",
      "so): too,very,how,really,nothing\n",
      "added): said.,added.,insisted,cautioned,says\n",
      "mr): tony,silk,gordon,insistence,silk's\n",
      "figure): dull,easing,flock,deterioration,enjoying\n",
      "roddick): goode,replaces,robinson,hazell,gomarsall\n",
      "income): council,wednesday's,9.5,variety,ces\n",
      "wins): century.critics,showdj,watford,october's,coordinator\n",
      "attempt): h.,veb,7bn,tony's,apacs\n",
      "that.): watched,agree,charming,vulnerability.internet,mullen\n",
      "wide): versions.japan,messaging,bewildering,vast,wider\n",
      "nominated): negar,aspiration,intervention,backfired,â£25\n",
      "bankruptcy): yourself,bertelsmann's,fought,moves,gasp\n",
      "highest): massachusetts,efforts,revamped,salaries,june's\n",
      "james): thompson,duncan,rowntree,bath,walter\n",
      "separate): infrastructure.the,pair's,.its,heirs,harbouring\n",
      "gadgets): judge.,youngsters,wavelength,bases.,respond\n",
      "lives): ukip's,sebastien,restaurant,therese,language.\n",
      "millions): maker's,customers,hat,en,petty\n",
      "confident): happen,going,happy,hesitate.,delighted\n",
      "\n",
      "\n",
      "2227/2227 [==============================] - 42s 19ms/step - loss: 0.3636\n",
      "Epoch: 5/5 started\n",
      "   2225/Unknown - 42s 19ms/step - loss: 0.3411labour): conservative,touch.wales,eurosceptic,conservatives,1.3bn\n",
      "based): concertus,holds,envelopes,partnered,pie\n",
      "has): had,repeatedly,wooing,protested,yarnton\n",
      "you): we,i,they,why,we'll\n",
      "also): already,never,initially,reportedly,been\n",
      "between): scoring,surging,below,sharp,unlawfully\n",
      "go): play,let,give,understand,see\n",
      "film): movie,mgm,philharmonic,honouractor,glazer's\n",
      "who): eventually,changing.,marketed.,binyamin,performing\n",
      "another): birmingham,position,tricky,testing,comeback\n",
      "make): give,persuade,do,feel,great.\n",
      "since): in,2002.,june,hitting,29\n",
      "me): him,this.,tories,adequately,why\n",
      "so): too,how,very,corporations,extremely\n",
      "added): said.,insisted,added.,believed,cautioned\n",
      "mr): tony,gordon,silk,insistence,acknowledged\n",
      "figure): dull,deterioration,problem.,battlethat's,armband\n",
      "roddick): robinson,goode,gomarsall,nadal,o'connell\n",
      "income): council,rises.he,evasion,inheritance,variety\n",
      "wins): watford,complaintbarcelona,showdj,eldridge,74th\n",
      "attempt): shakesa,exploded,incorporates,000.analysts,peoplesoft\n",
      "that.): watched,talk,condemned,accomplished,pepito\n",
      "wide): versions.japan,everyday,taste,reviewing,regaining\n",
      "nominated): negar,aspiration,greats,â£25,hopesmike\n",
      "bankruptcy): copy,scheme.,xstrata's,yourself,950m\n",
      "highest): massachusetts,0.27,victim.,bureaucracy,opportunities.\n",
      "james): duncan,johnson,rowntree,thompson,jon\n",
      "separate): croucher,infrastructure.the,languages,organisation.,darker\n",
      "gadgets): captaincy,â£227bn,bombing.,habit,resurgence\n",
      "lives): language.,intellect,ukip's,meals,products\n",
      "millions): 950m,mainstream.smaller,15bn,terrorists',minimixa\n",
      "confident): delighted,going,glad,happen,happy\n",
      "\n",
      "\n",
      "2227/2227 [==============================] - 42s 19ms/step - loss: 0.3411\n"
     ]
    }
   ],
   "source": [
    "cbow_validation_callback = ValidationCallback(valid_term_ids, cbow_model, tokenizer)\n",
    "\n",
    "for ei in range(epochs):\n",
    "    print(f\"Epoch: {ei+1}/{epochs} started\")\n",
    "    news_cbow_gen = cbow_data_generator(news_sequences, window_size, batch_size, negative_samples)\n",
    "    cbow_model.fit(\n",
    "        news_cbow_gen, \n",
    "        epochs=1, \n",
    "        callbacks=cbow_validation_callback,         \n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('tensorflow_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c46df576936c8255b1c2554cedc1eb44982b877a37736dc6e33d18af7b82b03d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
